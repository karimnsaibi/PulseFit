{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PulseFit ETL Process: From Raw to Clean Data\n",
    "**Objective**: Extract data from raw CSV files, perform cleaning and transformations, and load the results into a processed format suitable for BI analysis.\n",
    "\n",
    "## Phase 1: Extraction & Initial Inspection\n",
    "In this phase, we load our datasets and perform a high-level scan to understand the quality of the data we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Paths\n",
    "RAW_DATA_PATH = \"data/raw/\"\n",
    "PROCESSED_DATA_PATH = \"data/processed/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Members: 500 rows\n",
      "- Visits: 1998 rows\n",
      "- Payments: 1500 rows\n",
      "- Trainers: 30 rows\n",
      "- Classes: 60 rows\n",
      "- Bookings: 1200 rows\n"
     ]
    }
   ],
   "source": [
    "members_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"members_raw.csv\"))\n",
    "visits_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"visits_raw.csv\"))\n",
    "payments_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"payments_raw.csv\"))\n",
    "trainers_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"trainers_raw.csv\"))\n",
    "classes_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"classes_raw.csv\"))\n",
    "bookings_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, \"bookings_raw.csv\"))\n",
    "\n",
    "print(f\"- Members: {members_raw.shape[0]} rows\")\n",
    "print(f\"- Visits: {visits_raw.shape[0]} rows\")\n",
    "print(f\"- Payments: {payments_raw.shape[0]} rows\")\n",
    "print(f\"- Trainers: {trainers_raw.shape[0]} rows\")\n",
    "print(f\"- Classes: {classes_raw.shape[0]} rows\")\n",
    "print(f\"- Bookings: {bookings_raw.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Initial Data Quality Audit\n",
    "Let's look at the structure and find basic issues like missing values and wrong data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Members Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   member_id        500 non-null    object\n",
      " 1   full_name        500 non-null    object\n",
      " 2   email            478 non-null    object\n",
      " 3   phone_number     500 non-null    object\n",
      " 4   gender           496 non-null    object\n",
      " 5   join_date        500 non-null    object\n",
      " 6   membership_type  500 non-null    object\n",
      " 7   status           500 non-null    object\n",
      " 8   home_branch      500 non-null    object\n",
      " 9   birth_year       500 non-null    int64 \n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 39.2+ KB\n",
      "None\n",
      "\n",
      "--- Visits Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1998 entries, 0 to 1997\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   visit_id        1998 non-null   object\n",
      " 1   member_id       1998 non-null   object\n",
      " 2   branch          1998 non-null   object\n",
      " 3   check_in_time   1998 non-null   object\n",
      " 4   check_out_time  1822 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 78.2+ KB\n",
      "None\n",
      "\n",
      "--- Payments Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   payment_id       1500 non-null   object\n",
      " 1   member_id        1500 non-null   object\n",
      " 2   date             1500 non-null   object\n",
      " 3   amount           1500 non-null   int64 \n",
      " 4   payment_method   1500 non-null   object\n",
      " 5   membership_type  1500 non-null   object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 70.4+ KB\n",
      "None\n",
      "\n",
      "--- Trainers Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   trainer_id      30 non-null     object\n",
      " 1   full_name       30 non-null     object\n",
      " 2   specialization  29 non-null     object\n",
      " 3   branch          30 non-null     object\n",
      " 4   hire_date       30 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.3+ KB\n",
      "None\n",
      "\n",
      "--- Classes Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   class_id      60 non-null     object\n",
      " 1   class_name    60 non-null     object\n",
      " 2   trainer_id    60 non-null     object\n",
      " 3   branch        60 non-null     object\n",
      " 4   day_of_week   60 non-null     object\n",
      " 5   time_slot     60 non-null     object\n",
      " 6   max_capacity  60 non-null     int64 \n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.4+ KB\n",
      "None\n",
      "\n",
      "--- Bookings Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   booking_id    1200 non-null   object\n",
      " 1   member_id     1200 non-null   object\n",
      " 2   class_id      1200 non-null   object\n",
      " 3   status        1200 non-null   object\n",
      " 4   booking_date  1200 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Members Info ---\")\n",
    "print(members_raw.info())\n",
    "print(\"\\n--- Visits Info ---\")\n",
    "print(visits_raw.info())\n",
    "print(\"\\n--- Payments Info ---\")\n",
    "print(payments_raw.info())\n",
    "print(\"\\n--- Trainers Info ---\")\n",
    "print(trainers_raw.info())\n",
    "print(\"\\n--- Classes Info ---\")\n",
    "print(classes_raw.info())\n",
    "print(\"\\n--- Bookings Info ---\")\n",
    "print(bookings_raw.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Identifying Inconsistencies\n",
    "Scanning for human errors (branches, gender, types) across all tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Branches (Members): ['Nabeul Plage' 'Sousse Corniche' 'Bizerte Port' 'Sousse' 'Bizert'\n",
      " 'Sfax_Center' 'Tunis Lake' 'Sfax Center' 'tunis lake' 'Nabeul']\n",
      "Unique Branches (Trainers): ['Sfax_Center' 'Sfax Center' 'tunis lake' 'Nabeul' 'Bizerte Port' 'Sousse'\n",
      " 'Tunis Lake' 'Bizert']\n",
      "Unique Branches (Classes): ['Sousse' 'Bizert' 'Sfax_Center' 'Sfax Center' 'tunis lake' 'Bizerte Port'\n",
      " 'Tunis Lake']\n",
      "Unique Genders (Members): ['M' 'F' 'Femal' 'Male' nan]\n",
      "Membership Types (Members): ['Student' 'VIP' '6-Month' 'Annual' 'Monthly' 'ANNUAL' '6-MONTH' 'MONTHLY'\n",
      " 'STUDENT']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Branches (Members):\", members_raw['home_branch'].unique())\n",
    "print(\"Unique Branches (Trainers):\", trainers_raw['branch'].unique())\n",
    "print(\"Unique Branches (Classes):\", classes_raw['branch'].unique())\n",
    "print(\"Unique Genders (Members):\", members_raw['gender'].unique())\n",
    "print(\"Membership Types (Members):\", members_raw['membership_type'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Detailed Quality Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Missing Values Check (Members):\n",
      "member_id           0\n",
      "full_name           0\n",
      "email              22\n",
      "phone_number        0\n",
      "gender              4\n",
      "join_date           0\n",
      "membership_type     0\n",
      "status              0\n",
      "home_branch         0\n",
      "birth_year          0\n",
      "dtype: int64\n",
      "\n",
      "   Duplicate Members Check:\n",
      "Found 257 potential duplicate records.\n",
      "\n",
      "   Value Range Checks:\n",
      "Payments Amount Min/Max: -4500 / 8000\n",
      "Visits Check-out Missing: 176\n"
     ]
    }
   ],
   "source": [
    "print(\"     Missing Values Check (Members):\")\n",
    "print(members_raw.isnull().sum())\n",
    "\n",
    "print(\"\\n   Duplicate Members Check:\")\n",
    "dups = members_raw[members_raw.duplicated(subset=['full_name', 'email'], keep=False)]\n",
    "print(f\"Found {len(dups)} potential duplicate records.\")\n",
    "\n",
    "print(\"\\n   Value Range Checks:\")\n",
    "print(\"Payments Amount Min/Max:\", payments_raw['amount'].min(), \"/\", payments_raw['amount'].max())\n",
    "print(\"Visits Check-out Missing:\", visits_raw['check_out_time'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Data Cleaning & Transformation\n",
    "\n",
    "### 2.1 Cleaning Members Data\n",
    "- Normalize Branch Names\n",
    "- Fix Gender Categories\n",
    "- Normalize Phone Numbers\n",
    "- Remove Duplicates\n",
    "- Handle missing emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members dataset after cleaning: 352 rows\n"
     ]
    }
   ],
   "source": [
    "members_clean = members_raw.copy()\n",
    "\n",
    "# 1. Standardize Branch names\n",
    "branch_map = {\n",
    "    'tunis lake': 'Tunis Lake', \n",
    "    'Sfax_Center': 'Sfax Center', \n",
    "    'Sousse': 'Sousse Corniche', \n",
    "    'Nabeul': 'Nabeul Plage',\n",
    "    'Bizert': 'Bizerte Port'\n",
    "}\n",
    "members_clean['home_branch'] = members_clean['home_branch'].replace(branch_map)\n",
    "\n",
    "# 2. Standardize Gender\n",
    "members_clean['gender'] = members_clean['gender'].replace({'Male': 'M', 'Femal': 'F'})\n",
    "members_clean['gender'] = members_clean['gender'].fillna('U')\n",
    "\n",
    "# 3. Normalize Phone Numbers\n",
    "def normalize_phone(phone):\n",
    "    digits = re.sub(r'\\D', '', str(phone))\n",
    "    clean = digits[-8:]\n",
    "    return clean if len(clean) == 8 else 'INVALID'\n",
    "\n",
    "members_clean['phone_number'] = members_clean['phone_number'].apply(normalize_phone)\n",
    "\n",
    "# 4. Remove Duplicates\n",
    "members_clean = members_clean.drop_duplicates(subset=['full_name', 'email'], keep='first')\n",
    "\n",
    "print(f\"Members dataset after cleaning: {members_clean.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cleaning Visits Data\n",
    "- Convert timestamps to datetime\n",
    "- Normalize branch names\n",
    "- Smart Imputation for check-out\n",
    "- Filter logic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits dataset after cleaning: 1998 rows\n"
     ]
    }
   ],
   "source": [
    "visits_clean = visits_raw.copy()\n",
    "visits_clean['check_in_time'] = pd.to_datetime(visits_clean['check_in_time'])\n",
    "visits_clean['check_out_time'] = pd.to_datetime(visits_clean['check_out_time'])\n",
    "visits_clean['branch'] = visits_clean['branch'].replace(branch_map)\n",
    "\n",
    "# Filter and create duration\n",
    "temp_df = visits_clean.dropna(subset=['check_out_time']).copy()\n",
    "temp_df['duration'] = temp_df['check_out_time'] - temp_df['check_in_time']\n",
    "temp_df = temp_df[temp_df['duration'] > pd.Timedelta(0)]\n",
    "\n",
    "medians_map = temp_df.groupby('branch')['duration'].median()\n",
    "global_median = temp_df['duration'].median()\n",
    "\n",
    "mask = visits_clean['check_out_time'].isnull()\n",
    "visits_clean.loc[mask, 'check_out_time'] = visits_clean.loc[mask, 'check_in_time'] + \\\n",
    "    visits_clean.loc[mask, 'branch'].map(medians_map).fillna(global_median)\n",
    "\n",
    "print(f\"Visits dataset after cleaning: {visits_clean.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cleaning Payments Data\n",
    "- Remove negative amounts\n",
    "- Fix outlier typos (10x)\n",
    "- Capitalize membership types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payments dataset after cleaning: 1481 rows\n"
     ]
    }
   ],
   "source": [
    "payments_clean = payments_raw.copy()\n",
    "payments_clean = payments_clean[payments_clean['amount'] > 0]\n",
    "payments_clean.loc[payments_clean['amount'] > 1500, 'amount'] = payments_clean['amount'] / 10\n",
    "payments_clean['membership_type'] = payments_clean['membership_type'].str.capitalize()\n",
    "\n",
    "print(f\"Payments dataset after cleaning: {payments_clean.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Cleaning Trainers, Classes & Bookings\n",
    "- Normalize Branch Names\n",
    "- Fill missing specializations\n",
    "- Standardize dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainers clean: 30 rows\n",
      "Classes clean: 60 rows\n",
      "Bookings clean: 1200 rows\n"
     ]
    }
   ],
   "source": [
    "trainers_clean = trainers_raw.copy()\n",
    "trainers_clean['branch'] = trainers_clean['branch'].replace(branch_map)\n",
    "trainers_clean['specialization'] = trainers_clean['specialization'].fillna(\"General\")\n",
    "\n",
    "classes_clean = classes_raw.copy()\n",
    "classes_clean['branch'] = classes_clean['branch'].replace(branch_map)\n",
    "\n",
    "bookings_clean = bookings_raw.copy()\n",
    "bookings_clean['booking_date'] = pd.to_datetime(bookings_clean['booking_date'])\n",
    "\n",
    "print(f\"Trainers clean: {trainers_clean.shape[0]} rows\")\n",
    "print(f\"Classes clean: {classes_clean.shape[0]} rows\")\n",
    "print(f\"Bookings clean: {bookings_clean.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Loading (Saving results)\n",
    "Now we save the full PulseFit clean ecosystem to `data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Complete! All 6 clean PulseFit datasets saved.\n"
     ]
    }
   ],
   "source": [
    "members_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"members_clean.csv\"), index=False)\n",
    "visits_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"visits_clean.csv\"), index=False)\n",
    "payments_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"payments_clean.csv\"), index=False)\n",
    "trainers_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"trainers_clean.csv\"), index=False)\n",
    "classes_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"classes_clean.csv\"), index=False)\n",
    "bookings_clean.to_csv(os.path.join(PROCESSED_DATA_PATH, \"bookings_clean.csv\"), index=False)\n",
    "\n",
    "print(\"ETL Complete! All 6 clean PulseFit datasets saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi_py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
